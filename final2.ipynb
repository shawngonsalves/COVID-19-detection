{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawngonsalves/COVID-19-detection/blob/master/final2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yf2-V-9eLW_",
        "colab_type": "code",
        "outputId": "6ec6f730-76f7-4d56-e8d9-c107df5d8a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIbxnQRJe6Nn",
        "colab_type": "code",
        "outputId": "8c9f4e54-30bd-474b-d8a6-b6e2740d3815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# USAGE\n",
        "# python train.py --dataset dataset\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# construct the argument parser and parse the arguments\n",
        "\n",
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "INIT_LR = 1e-3\n",
        "EPOCHS = 600\n",
        "BS = 100\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images('/content/drive/My Drive/keras-covid-19/dataset/'))\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the image, swap color channels, and resize it to be a fixed\n",
        "\t# 224x224 pixels while ignoring aspect ratio\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\timage = cv2.resize(image, (224, 224))\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)\n",
        "\n",
        "# convert the data and labels to NumPy arrays while scaling the pixel\n",
        "# intensities to the range [0, 255]\n",
        "data = np.array(data) / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42)\n",
        "\n",
        "# initialize the training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=15,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "# load the VGG16 network, ensuring the head FC layer sets are left\n",
        "# off\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(64, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainAug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "\n",
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig('/content/drive/My Drive/keras-covid-19/plot1.png')\n",
        "\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving COVID-19 detector model...\")\n",
        "model.save('/content/drive/My Drive/keras-covid-19/Final.model', save_format=\"h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "[INFO] compiling model...\n",
            "[INFO] training head...\n",
            "WARNING:tensorflow:From <ipython-input-3-6724c305d533>:108: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/600\n",
            "12/12 [==============================] - 15s 1s/step - loss: 0.6399 - accuracy: 0.6975 - val_loss: 0.4664 - val_accuracy: 0.8478\n",
            "Epoch 2/600\n",
            "12/12 [==============================] - 12s 967ms/step - loss: 0.4681 - accuracy: 0.8502 - val_loss: 0.3545 - val_accuracy: 0.8478\n",
            "Epoch 3/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3739 - accuracy: 0.8653 - val_loss: 0.2825 - val_accuracy: 0.8727\n",
            "Epoch 4/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2918 - accuracy: 0.8897 - val_loss: 0.2352 - val_accuracy: 0.8975\n",
            "Epoch 5/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2368 - accuracy: 0.9074 - val_loss: 0.2037 - val_accuracy: 0.9130\n",
            "Epoch 6/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2095 - accuracy: 0.9209 - val_loss: 0.1762 - val_accuracy: 0.9379\n",
            "Epoch 7/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.1811 - accuracy: 0.9327 - val_loss: 0.1572 - val_accuracy: 0.9379\n",
            "Epoch 8/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.1718 - accuracy: 0.9411 - val_loss: 0.1428 - val_accuracy: 0.9503\n",
            "Epoch 9/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.1345 - accuracy: 0.9613 - val_loss: 0.1330 - val_accuracy: 0.9472\n",
            "Epoch 10/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.1380 - accuracy: 0.9529 - val_loss: 0.1235 - val_accuracy: 0.9596\n",
            "Epoch 11/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.1276 - accuracy: 0.9554 - val_loss: 0.1156 - val_accuracy: 0.9627\n",
            "Epoch 12/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.1073 - accuracy: 0.9731 - val_loss: 0.1084 - val_accuracy: 0.9627\n",
            "Epoch 13/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.1193 - accuracy: 0.9554 - val_loss: 0.1037 - val_accuracy: 0.9627\n",
            "Epoch 14/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0994 - accuracy: 0.9700 - val_loss: 0.1006 - val_accuracy: 0.9689\n",
            "Epoch 15/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.1050 - accuracy: 0.9646 - val_loss: 0.0963 - val_accuracy: 0.9658\n",
            "Epoch 16/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.1073 - accuracy: 0.9621 - val_loss: 0.0935 - val_accuracy: 0.9720\n",
            "Epoch 17/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0948 - accuracy: 0.9722 - val_loss: 0.0892 - val_accuracy: 0.9689\n",
            "Epoch 18/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0830 - accuracy: 0.9747 - val_loss: 0.0853 - val_accuracy: 0.9752\n",
            "Epoch 19/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0867 - accuracy: 0.9756 - val_loss: 0.0832 - val_accuracy: 0.9783\n",
            "Epoch 20/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0928 - accuracy: 0.9630 - val_loss: 0.0806 - val_accuracy: 0.9720\n",
            "Epoch 21/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0745 - accuracy: 0.9781 - val_loss: 0.0788 - val_accuracy: 0.9783\n",
            "Epoch 22/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0864 - accuracy: 0.9756 - val_loss: 0.0758 - val_accuracy: 0.9783\n",
            "Epoch 23/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0816 - accuracy: 0.9739 - val_loss: 0.0746 - val_accuracy: 0.9783\n",
            "Epoch 24/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0768 - accuracy: 0.9747 - val_loss: 0.0712 - val_accuracy: 0.9814\n",
            "Epoch 25/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0725 - accuracy: 0.9790 - val_loss: 0.0686 - val_accuracy: 0.9783\n",
            "Epoch 26/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0644 - accuracy: 0.9806 - val_loss: 0.0668 - val_accuracy: 0.9845\n",
            "Epoch 27/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0686 - accuracy: 0.9808 - val_loss: 0.0648 - val_accuracy: 0.9845\n",
            "Epoch 28/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0658 - accuracy: 0.9764 - val_loss: 0.0630 - val_accuracy: 0.9783\n",
            "Epoch 29/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.0620 - val_accuracy: 0.9845\n",
            "Epoch 30/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0611 - accuracy: 0.9815 - val_loss: 0.0599 - val_accuracy: 0.9845\n",
            "Epoch 31/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0622 - accuracy: 0.9798 - val_loss: 0.0590 - val_accuracy: 0.9845\n",
            "Epoch 32/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0743 - accuracy: 0.9731 - val_loss: 0.0582 - val_accuracy: 0.9814\n",
            "Epoch 33/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0604 - accuracy: 0.9815 - val_loss: 0.0559 - val_accuracy: 0.9876\n",
            "Epoch 34/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0671 - accuracy: 0.9790 - val_loss: 0.0538 - val_accuracy: 0.9876\n",
            "Epoch 35/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0579 - accuracy: 0.9840 - val_loss: 0.0534 - val_accuracy: 0.9876\n",
            "Epoch 36/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.0526 - val_accuracy: 0.9876\n",
            "Epoch 37/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0549 - accuracy: 0.9865 - val_loss: 0.0513 - val_accuracy: 0.9876\n",
            "Epoch 38/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.0500 - val_accuracy: 0.9876\n",
            "Epoch 39/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0578 - accuracy: 0.9832 - val_loss: 0.0501 - val_accuracy: 0.9876\n",
            "Epoch 40/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0522 - accuracy: 0.9867 - val_loss: 0.0479 - val_accuracy: 0.9876\n",
            "Epoch 41/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0531 - accuracy: 0.9840 - val_loss: 0.0480 - val_accuracy: 0.9876\n",
            "Epoch 42/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0504 - accuracy: 0.9848 - val_loss: 0.0462 - val_accuracy: 0.9907\n",
            "Epoch 43/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0522 - accuracy: 0.9815 - val_loss: 0.0455 - val_accuracy: 0.9907\n",
            "Epoch 44/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0533 - accuracy: 0.9874 - val_loss: 0.0451 - val_accuracy: 0.9876\n",
            "Epoch 45/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0417 - accuracy: 0.9899 - val_loss: 0.0448 - val_accuracy: 0.9907\n",
            "Epoch 46/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0420 - accuracy: 0.9874 - val_loss: 0.0459 - val_accuracy: 0.9907\n",
            "Epoch 47/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 0.0443 - val_accuracy: 0.9907\n",
            "Epoch 48/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0508 - accuracy: 0.9857 - val_loss: 0.0450 - val_accuracy: 0.9907\n",
            "Epoch 49/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.0420 - val_accuracy: 0.9907\n",
            "Epoch 50/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0536 - accuracy: 0.9823 - val_loss: 0.0411 - val_accuracy: 0.9907\n",
            "Epoch 51/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0404 - val_accuracy: 0.9907\n",
            "Epoch 52/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0390 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9907\n",
            "Epoch 53/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.0400 - val_accuracy: 0.9907\n",
            "Epoch 54/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0482 - accuracy: 0.9857 - val_loss: 0.0402 - val_accuracy: 0.9907\n",
            "Epoch 55/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0478 - accuracy: 0.9832 - val_loss: 0.0398 - val_accuracy: 0.9907\n",
            "Epoch 56/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0390 - accuracy: 0.9882 - val_loss: 0.0387 - val_accuracy: 0.9907\n",
            "Epoch 57/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0422 - accuracy: 0.9874 - val_loss: 0.0383 - val_accuracy: 0.9907\n",
            "Epoch 58/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0350 - accuracy: 0.9899 - val_loss: 0.0408 - val_accuracy: 0.9938\n",
            "Epoch 59/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0419 - accuracy: 0.9891 - val_loss: 0.0375 - val_accuracy: 0.9907\n",
            "Epoch 60/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0461 - accuracy: 0.9823 - val_loss: 0.0372 - val_accuracy: 0.9907\n",
            "Epoch 61/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0426 - accuracy: 0.9874 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
            "Epoch 62/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0344 - accuracy: 0.9907 - val_loss: 0.0364 - val_accuracy: 0.9907\n",
            "Epoch 63/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0426 - accuracy: 0.9891 - val_loss: 0.0355 - val_accuracy: 0.9907\n",
            "Epoch 64/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0402 - accuracy: 0.9882 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
            "Epoch 65/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0445 - accuracy: 0.9882 - val_loss: 0.0353 - val_accuracy: 0.9907\n",
            "Epoch 66/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0419 - accuracy: 0.9892 - val_loss: 0.0371 - val_accuracy: 0.9969\n",
            "Epoch 67/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0338 - accuracy: 0.9907 - val_loss: 0.0347 - val_accuracy: 0.9907\n",
            "Epoch 68/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0297 - accuracy: 0.9933 - val_loss: 0.0342 - val_accuracy: 0.9938\n",
            "Epoch 69/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0339 - val_accuracy: 0.9938\n",
            "Epoch 70/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0247 - accuracy: 0.9966 - val_loss: 0.0332 - val_accuracy: 0.9907\n",
            "Epoch 71/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0419 - accuracy: 0.9899 - val_loss: 0.0353 - val_accuracy: 0.9938\n",
            "Epoch 72/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.0333 - val_accuracy: 0.9938\n",
            "Epoch 73/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0412 - accuracy: 0.9882 - val_loss: 0.0328 - val_accuracy: 0.9907\n",
            "Epoch 74/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0265 - accuracy: 0.9949 - val_loss: 0.0324 - val_accuracy: 0.9938\n",
            "Epoch 75/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.0317 - val_accuracy: 0.9907\n",
            "Epoch 76/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0388 - accuracy: 0.9907 - val_loss: 0.0333 - val_accuracy: 0.9969\n",
            "Epoch 77/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 0.0316 - val_accuracy: 0.9907\n",
            "Epoch 78/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0334 - accuracy: 0.9916 - val_loss: 0.0341 - val_accuracy: 0.9969\n",
            "Epoch 79/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0307 - val_accuracy: 0.9907\n",
            "Epoch 80/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0337 - accuracy: 0.9924 - val_loss: 0.0300 - val_accuracy: 0.9907\n",
            "Epoch 81/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 0.0318 - val_accuracy: 0.9969\n",
            "Epoch 82/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.0292 - val_accuracy: 0.9907\n",
            "Epoch 83/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0399 - accuracy: 0.9907 - val_loss: 0.0298 - val_accuracy: 0.9938\n",
            "Epoch 84/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.0301 - val_accuracy: 0.9969\n",
            "Epoch 85/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0205 - accuracy: 0.9958 - val_loss: 0.0289 - val_accuracy: 0.9938\n",
            "Epoch 86/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.0287 - val_accuracy: 0.9907\n",
            "Epoch 87/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 0.0295 - val_accuracy: 0.9969\n",
            "Epoch 88/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0300 - accuracy: 0.9949 - val_loss: 0.0285 - val_accuracy: 0.9938\n",
            "Epoch 89/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 0.0287 - val_accuracy: 0.9969\n",
            "Epoch 90/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.0276 - val_accuracy: 0.9938\n",
            "Epoch 91/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0275 - val_accuracy: 0.9938\n",
            "Epoch 92/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.0278 - val_accuracy: 0.9907\n",
            "Epoch 93/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.0270 - val_accuracy: 0.9907\n",
            "Epoch 94/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.0268 - val_accuracy: 0.9938\n",
            "Epoch 95/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0274 - val_accuracy: 0.9938\n",
            "Epoch 96/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 0.0278 - val_accuracy: 0.9938\n",
            "Epoch 97/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0276 - val_accuracy: 0.9938\n",
            "Epoch 98/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0328 - accuracy: 0.9907 - val_loss: 0.0274 - val_accuracy: 0.9907\n",
            "Epoch 99/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 0.0276 - val_accuracy: 0.9938\n",
            "Epoch 100/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0232 - accuracy: 0.9949 - val_loss: 0.0277 - val_accuracy: 0.9969\n",
            "Epoch 101/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.0264 - val_accuracy: 0.9907\n",
            "Epoch 102/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0296 - accuracy: 0.9924 - val_loss: 0.0272 - val_accuracy: 0.9969\n",
            "Epoch 103/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0211 - accuracy: 0.9975 - val_loss: 0.0258 - val_accuracy: 0.9907\n",
            "Epoch 104/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 0.0261 - val_accuracy: 0.9938\n",
            "Epoch 105/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.0263 - val_accuracy: 0.9907\n",
            "Epoch 106/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0292 - accuracy: 0.9941 - val_loss: 0.0261 - val_accuracy: 0.9907\n",
            "Epoch 107/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0255 - val_accuracy: 0.9907\n",
            "Epoch 108/600\n",
            "12/12 [==============================] - 12s 989ms/step - loss: 0.0302 - accuracy: 0.9907 - val_loss: 0.0247 - val_accuracy: 0.9907\n",
            "Epoch 109/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.0255 - val_accuracy: 0.9969\n",
            "Epoch 110/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0282 - accuracy: 0.9924 - val_loss: 0.0244 - val_accuracy: 0.9907\n",
            "Epoch 111/600\n",
            "12/12 [==============================] - 12s 972ms/step - loss: 0.0207 - accuracy: 0.9916 - val_loss: 0.0247 - val_accuracy: 0.9969\n",
            "Epoch 112/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 0.0239 - val_accuracy: 0.9907\n",
            "Epoch 113/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0264 - val_accuracy: 0.9969\n",
            "Epoch 114/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0291 - accuracy: 0.9924 - val_loss: 0.0234 - val_accuracy: 0.9907\n",
            "Epoch 115/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0188 - accuracy: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9907\n",
            "Epoch 116/600\n",
            "12/12 [==============================] - 12s 968ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0240 - val_accuracy: 0.9969\n",
            "Epoch 117/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0233 - val_accuracy: 0.9938\n",
            "Epoch 118/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0277 - accuracy: 0.9933 - val_loss: 0.0230 - val_accuracy: 0.9938\n",
            "Epoch 119/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0229 - val_accuracy: 0.9938\n",
            "Epoch 120/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0235 - val_accuracy: 0.9969\n",
            "Epoch 121/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.0226 - val_accuracy: 0.9907\n",
            "Epoch 122/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0217 - accuracy: 0.9958 - val_loss: 0.0224 - val_accuracy: 0.9907\n",
            "Epoch 123/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0243 - val_accuracy: 0.9969\n",
            "Epoch 124/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 0.0218 - val_accuracy: 0.9938\n",
            "Epoch 125/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0218 - val_accuracy: 0.9969\n",
            "Epoch 126/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.0212 - val_accuracy: 0.9907\n",
            "Epoch 127/600\n",
            "12/12 [==============================] - 12s 989ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0217 - val_accuracy: 0.9969\n",
            "Epoch 128/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0211 - val_accuracy: 0.9938\n",
            "Epoch 129/600\n",
            "12/12 [==============================] - 12s 968ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.0231 - val_accuracy: 0.9969\n",
            "Epoch 130/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0214 - val_accuracy: 0.9969\n",
            "Epoch 131/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.0211 - val_accuracy: 0.9907\n",
            "Epoch 132/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.0224 - val_accuracy: 0.9969\n",
            "Epoch 133/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0185 - accuracy: 0.9966 - val_loss: 0.0204 - val_accuracy: 0.9907\n",
            "Epoch 134/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0203 - val_accuracy: 0.9969\n",
            "Epoch 135/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0198 - val_accuracy: 0.9969\n",
            "Epoch 136/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0190 - accuracy: 0.9975 - val_loss: 0.0198 - val_accuracy: 0.9938\n",
            "Epoch 137/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 0.0229 - val_accuracy: 0.9969\n",
            "Epoch 138/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0208 - val_accuracy: 0.9907\n",
            "Epoch 139/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0201 - val_accuracy: 0.9907\n",
            "Epoch 140/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0203 - val_accuracy: 0.9969\n",
            "Epoch 141/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 0.0195 - val_accuracy: 0.9938\n",
            "Epoch 142/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.0222 - val_accuracy: 0.9969\n",
            "Epoch 143/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.0190 - val_accuracy: 0.9938\n",
            "Epoch 144/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0189 - val_accuracy: 0.9938\n",
            "Epoch 145/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.0188 - val_accuracy: 0.9938\n",
            "Epoch 146/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0116 - accuracy: 0.9983 - val_loss: 0.0193 - val_accuracy: 0.9938\n",
            "Epoch 147/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0195 - val_accuracy: 0.9907\n",
            "Epoch 148/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0236 - accuracy: 0.9958 - val_loss: 0.0192 - val_accuracy: 0.9969\n",
            "Epoch 149/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.0190 - val_accuracy: 0.9969\n",
            "Epoch 150/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.0190 - val_accuracy: 0.9969\n",
            "Epoch 151/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.0186 - val_accuracy: 0.9907\n",
            "Epoch 152/600\n",
            "12/12 [==============================] - 12s 960ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.0178 - val_accuracy: 0.9938\n",
            "Epoch 153/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0185 - accuracy: 0.9975 - val_loss: 0.0183 - val_accuracy: 0.9938\n",
            "Epoch 154/600\n",
            "12/12 [==============================] - 12s 968ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.0183 - val_accuracy: 0.9938\n",
            "Epoch 155/600\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.0185 - val_accuracy: 0.9969\n",
            "Epoch 156/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0181 - val_accuracy: 0.9938\n",
            "Epoch 157/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 0.0175 - val_accuracy: 0.9938\n",
            "Epoch 158/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0168 - accuracy: 0.9966 - val_loss: 0.0193 - val_accuracy: 0.9969\n",
            "Epoch 159/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0240 - accuracy: 0.9958 - val_loss: 0.0179 - val_accuracy: 0.9907\n",
            "Epoch 160/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 0.0170 - val_accuracy: 0.9938\n",
            "Epoch 161/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.0180 - val_accuracy: 0.9969\n",
            "Epoch 162/600\n",
            "12/12 [==============================] - 12s 964ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.0169 - val_accuracy: 0.9938\n",
            "Epoch 163/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.0170 - val_accuracy: 0.9938\n",
            "Epoch 164/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0163 - val_accuracy: 0.9938\n",
            "Epoch 165/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0191 - accuracy: 0.9924 - val_loss: 0.0199 - val_accuracy: 0.9969\n",
            "Epoch 166/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.0174 - val_accuracy: 0.9938\n",
            "Epoch 167/600\n",
            "12/12 [==============================] - 12s 965ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.0175 - val_accuracy: 0.9938\n",
            "Epoch 168/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0176 - val_accuracy: 0.9907\n",
            "Epoch 169/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0199 - accuracy: 0.9949 - val_loss: 0.0165 - val_accuracy: 0.9938\n",
            "Epoch 170/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0185 - accuracy: 0.9967 - val_loss: 0.0163 - val_accuracy: 0.9938\n",
            "Epoch 171/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0155 - val_accuracy: 0.9938\n",
            "Epoch 172/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.0166 - val_accuracy: 0.9938\n",
            "Epoch 173/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.0160 - val_accuracy: 0.9938\n",
            "Epoch 174/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.0154 - val_accuracy: 0.9938\n",
            "Epoch 175/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0165 - val_accuracy: 0.9969\n",
            "Epoch 176/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.0159 - val_accuracy: 0.9907\n",
            "Epoch 177/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.0147 - val_accuracy: 0.9938\n",
            "Epoch 178/600\n",
            "12/12 [==============================] - 12s 989ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.0146 - val_accuracy: 0.9938\n",
            "Epoch 179/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.0150 - val_accuracy: 0.9938\n",
            "Epoch 180/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0150 - val_accuracy: 0.9938\n",
            "Epoch 181/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.0158 - val_accuracy: 0.9969\n",
            "Epoch 182/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0159 - accuracy: 0.9924 - val_loss: 0.0137 - val_accuracy: 0.9938\n",
            "Epoch 183/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0171 - accuracy: 0.9933 - val_loss: 0.0148 - val_accuracy: 0.9969\n",
            "Epoch 184/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.0137 - val_accuracy: 0.9938\n",
            "Epoch 185/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.0138 - val_accuracy: 0.9969\n",
            "Epoch 186/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 0.0139 - val_accuracy: 0.9938\n",
            "Epoch 187/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0135 - accuracy: 0.9941 - val_loss: 0.0146 - val_accuracy: 0.9907\n",
            "Epoch 188/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.0140 - val_accuracy: 0.9938\n",
            "Epoch 189/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0134 - val_accuracy: 0.9938\n",
            "Epoch 190/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0138 - val_accuracy: 0.9938\n",
            "Epoch 191/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.0137 - val_accuracy: 0.9938\n",
            "Epoch 192/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0141 - val_accuracy: 0.9938\n",
            "Epoch 193/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.0138 - val_accuracy: 0.9938\n",
            "Epoch 194/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0153 - val_accuracy: 0.9907\n",
            "Epoch 195/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0151 - val_accuracy: 0.9969\n",
            "Epoch 196/600\n",
            "12/12 [==============================] - 12s 1000ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.0150 - val_accuracy: 0.9907\n",
            "Epoch 197/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0143 - val_accuracy: 0.9969\n",
            "Epoch 198/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0145 - val_accuracy: 0.9907\n",
            "Epoch 199/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0100 - accuracy: 0.9992 - val_loss: 0.0132 - val_accuracy: 0.9969\n",
            "Epoch 200/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0153 - val_accuracy: 0.9907\n",
            "Epoch 201/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0155 - val_accuracy: 0.9969\n",
            "Epoch 202/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.0147 - val_accuracy: 0.9907\n",
            "Epoch 203/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.0145 - val_accuracy: 0.9969\n",
            "Epoch 204/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.0132 - val_accuracy: 0.9907\n",
            "Epoch 205/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0114 - val_accuracy: 0.9969\n",
            "Epoch 206/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.0113 - val_accuracy: 0.9969\n",
            "Epoch 207/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.0112 - val_accuracy: 0.9938\n",
            "Epoch 208/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.0117 - val_accuracy: 0.9938\n",
            "Epoch 209/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.0113 - val_accuracy: 0.9938\n",
            "Epoch 210/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.0109 - val_accuracy: 0.9969\n",
            "Epoch 211/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
            "Epoch 212/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
            "Epoch 213/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.0113 - val_accuracy: 0.9938\n",
            "Epoch 214/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.0106 - val_accuracy: 0.9938\n",
            "Epoch 215/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
            "Epoch 216/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.0149 - val_accuracy: 0.9907\n",
            "Epoch 217/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0111 - val_accuracy: 0.9938\n",
            "Epoch 218/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0172 - accuracy: 0.9983 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
            "Epoch 219/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.0124 - val_accuracy: 0.9907\n",
            "Epoch 220/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0104 - val_accuracy: 0.9969\n",
            "Epoch 221/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0113 - val_accuracy: 0.9938\n",
            "Epoch 222/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
            "Epoch 223/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.0111 - val_accuracy: 0.9938\n",
            "Epoch 224/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0119 - val_accuracy: 0.9969\n",
            "Epoch 225/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0142 - val_accuracy: 0.9907\n",
            "Epoch 226/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
            "Epoch 227/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0132 - val_accuracy: 0.9907\n",
            "Epoch 228/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
            "Epoch 229/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0106 - val_accuracy: 0.9938\n",
            "Epoch 230/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.0108 - val_accuracy: 0.9969\n",
            "Epoch 231/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0106 - val_accuracy: 0.9969\n",
            "Epoch 232/600\n",
            "12/12 [==============================] - 12s 972ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0106 - val_accuracy: 0.9969\n",
            "Epoch 233/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.0101 - val_accuracy: 0.9938\n",
            "Epoch 234/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0107 - val_accuracy: 0.9938\n",
            "Epoch 235/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0098 - val_accuracy: 0.9938\n",
            "Epoch 236/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0107 - val_accuracy: 0.9969\n",
            "Epoch 237/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0087 - val_accuracy: 0.9969\n",
            "Epoch 238/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9938\n",
            "Epoch 239/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0088 - val_accuracy: 0.9938\n",
            "Epoch 240/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
            "Epoch 241/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9969\n",
            "Epoch 242/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.0087 - val_accuracy: 0.9969\n",
            "Epoch 243/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0088 - val_accuracy: 0.9938\n",
            "Epoch 244/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0086 - val_accuracy: 0.9969\n",
            "Epoch 245/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0096 - val_accuracy: 0.9969\n",
            "Epoch 246/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0089 - val_accuracy: 0.9938\n",
            "Epoch 247/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0071 - accuracy: 0.9966 - val_loss: 0.0106 - val_accuracy: 0.9938\n",
            "Epoch 248/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0097 - val_accuracy: 0.9969\n",
            "Epoch 249/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0096 - val_accuracy: 0.9938\n",
            "Epoch 250/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.0083 - val_accuracy: 0.9969\n",
            "Epoch 251/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.0091 - val_accuracy: 0.9938\n",
            "Epoch 252/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
            "Epoch 253/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.0119 - val_accuracy: 0.9907\n",
            "Epoch 254/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0100 - val_accuracy: 0.9969\n",
            "Epoch 255/600\n",
            "12/12 [==============================] - 12s 1000ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0104 - val_accuracy: 0.9938\n",
            "Epoch 256/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.0095 - val_accuracy: 0.9969\n",
            "Epoch 257/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0075 - accuracy: 0.9966 - val_loss: 0.0085 - val_accuracy: 0.9938\n",
            "Epoch 258/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0089 - val_accuracy: 0.9938\n",
            "Epoch 259/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.0092 - val_accuracy: 0.9938\n",
            "Epoch 260/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0090 - val_accuracy: 0.9938\n",
            "Epoch 261/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 0.0100 - val_accuracy: 0.9969\n",
            "Epoch 262/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0091 - val_accuracy: 0.9938\n",
            "Epoch 263/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0081 - val_accuracy: 0.9938\n",
            "Epoch 264/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0080 - val_accuracy: 0.9938\n",
            "Epoch 265/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.0081 - val_accuracy: 0.9969\n",
            "Epoch 266/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0112 - val_accuracy: 0.9969\n",
            "Epoch 267/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0081 - val_accuracy: 0.9969\n",
            "Epoch 268/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9938\n",
            "Epoch 269/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0079 - val_accuracy: 0.9969\n",
            "Epoch 270/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0104 - val_accuracy: 0.9969\n",
            "Epoch 271/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0070 - val_accuracy: 0.9969\n",
            "Epoch 272/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0078 - val_accuracy: 0.9969\n",
            "Epoch 273/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 274/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 275/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 276/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9969\n",
            "Epoch 277/600\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0068 - val_accuracy: 0.9969\n",
            "Epoch 278/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0066 - val_accuracy: 0.9969\n",
            "Epoch 279/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0062 - accuracy: 0.9966 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 280/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0094 - val_accuracy: 0.9969\n",
            "Epoch 281/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0110 - val_accuracy: 0.9938\n",
            "Epoch 282/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0088 - val_accuracy: 0.9969\n",
            "Epoch 283/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0079 - accuracy: 0.9958 - val_loss: 0.0123 - val_accuracy: 0.9938\n",
            "Epoch 284/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0102 - val_accuracy: 0.9969\n",
            "Epoch 285/600\n",
            "12/12 [==============================] - 12s 971ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.0070 - val_accuracy: 0.9969\n",
            "Epoch 286/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0070 - val_accuracy: 0.9969\n",
            "Epoch 287/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 288/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 289/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9969\n",
            "Epoch 290/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 291/600\n",
            "12/12 [==============================] - 12s 989ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 292/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
            "Epoch 293/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.0077 - val_accuracy: 0.9969\n",
            "Epoch 294/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0093 - accuracy: 0.9958 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 295/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 296/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 297/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0069 - val_accuracy: 0.9969\n",
            "Epoch 298/600\n",
            "12/12 [==============================] - 12s 968ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.0063 - val_accuracy: 0.9969\n",
            "Epoch 299/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 0.9969\n",
            "Epoch 300/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 0.9969\n",
            "Epoch 301/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 302/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0097 - accuracy: 0.9949 - val_loss: 0.0071 - val_accuracy: 0.9969\n",
            "Epoch 303/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 304/600\n",
            "12/12 [==============================] - 12s 1000ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 305/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9969\n",
            "Epoch 306/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0093 - val_accuracy: 0.9969\n",
            "Epoch 307/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0064 - val_accuracy: 0.9969\n",
            "Epoch 308/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 309/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 310/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0066 - accuracy: 0.9966 - val_loss: 0.0076 - val_accuracy: 0.9969\n",
            "Epoch 311/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 312/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 0.9969\n",
            "Epoch 313/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 314/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9969\n",
            "Epoch 315/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 316/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0083 - val_accuracy: 0.9969\n",
            "Epoch 317/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 318/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0110 - val_accuracy: 0.9938\n",
            "Epoch 319/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 320/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0069 - val_accuracy: 0.9969\n",
            "Epoch 321/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 322/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9969\n",
            "Epoch 323/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 324/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 325/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9969\n",
            "Epoch 326/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 327/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9969\n",
            "Epoch 328/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 329/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9969\n",
            "Epoch 330/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.0101 - val_accuracy: 0.9938\n",
            "Epoch 331/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.0121 - val_accuracy: 0.9938\n",
            "Epoch 332/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0054 - val_accuracy: 0.9969\n",
            "Epoch 333/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0069 - val_accuracy: 0.9969\n",
            "Epoch 334/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 335/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 336/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 337/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 338/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0050 - accuracy: 0.9975 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 339/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 0.0073 - val_accuracy: 0.9969\n",
            "Epoch 340/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 341/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9969\n",
            "Epoch 342/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 343/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 344/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0062 - accuracy: 0.9975 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 345/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 346/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9969\n",
            "Epoch 347/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 348/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 349/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9969\n",
            "Epoch 350/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 351/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 352/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9969\n",
            "Epoch 353/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 354/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 355/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0052 - val_accuracy: 0.9969\n",
            "Epoch 356/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 357/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 358/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0057 - val_accuracy: 0.9969\n",
            "Epoch 359/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9969\n",
            "Epoch 360/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0063 - val_accuracy: 0.9969\n",
            "Epoch 361/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 362/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0058 - val_accuracy: 0.9969\n",
            "Epoch 363/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0047 - accuracy: 0.9975 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 364/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0044 - accuracy: 0.9975 - val_loss: 0.0094 - val_accuracy: 0.9969\n",
            "Epoch 365/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 366/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 367/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9969\n",
            "Epoch 368/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 369/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 370/600\n",
            "12/12 [==============================] - 12s 989ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 371/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 372/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 373/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9969\n",
            "Epoch 374/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 375/600\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 376/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 377/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9969\n",
            "Epoch 378/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9969\n",
            "Epoch 379/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 380/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9969\n",
            "Epoch 381/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9969\n",
            "Epoch 382/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 383/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 384/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 385/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 386/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9969\n",
            "Epoch 387/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 388/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 389/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 390/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9969\n",
            "Epoch 391/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 392/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 393/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 394/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 395/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9969\n",
            "Epoch 396/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 397/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 398/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.0040 - val_accuracy: 0.9969\n",
            "Epoch 399/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0050 - accuracy: 0.9975 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 400/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 0.9969\n",
            "Epoch 401/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 402/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 403/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 404/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 405/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 406/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9969\n",
            "Epoch 407/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9969\n",
            "Epoch 408/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 409/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 410/600\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9969\n",
            "Epoch 411/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 412/600\n",
            "12/12 [==============================] - 12s 960ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9969\n",
            "Epoch 413/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 414/600\n",
            "12/12 [==============================] - 12s 972ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 415/600\n",
            "12/12 [==============================] - 12s 989ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 416/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9969\n",
            "Epoch 417/600\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.0075 - accuracy: 0.9967 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 418/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 419/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 420/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 421/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 422/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 423/600\n",
            "12/12 [==============================] - 12s 972ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 424/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 425/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0036 - accuracy: 0.9983 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 426/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9969\n",
            "Epoch 427/600\n",
            "12/12 [==============================] - 12s 968ms/step - loss: 0.0057 - accuracy: 0.9966 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 428/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 429/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 430/600\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 431/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 432/600\n",
            "12/12 [==============================] - 12s 968ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 433/600\n",
            "12/12 [==============================] - 12s 971ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 434/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 435/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 436/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 437/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 438/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9969\n",
            "Epoch 439/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0034 - accuracy: 0.9983 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 440/600\n",
            "12/12 [==============================] - 12s 967ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 441/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 442/600\n",
            "12/12 [==============================] - 12s 972ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 443/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 444/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 445/600\n",
            "12/12 [==============================] - 11s 958ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9969\n",
            "Epoch 446/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 447/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 448/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 449/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 450/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0041 - accuracy: 0.9975 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 451/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 452/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9969\n",
            "Epoch 453/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 454/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 455/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 456/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 457/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 458/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 459/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 460/600\n",
            "12/12 [==============================] - 12s 971ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 461/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0030 - accuracy: 0.9983 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 462/600\n",
            "12/12 [==============================] - 12s 960ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9969\n",
            "Epoch 463/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 464/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9969\n",
            "Epoch 465/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9969\n",
            "Epoch 466/600\n",
            "12/12 [==============================] - 12s 968ms/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 467/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 468/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 469/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 470/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 471/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 472/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9969\n",
            "Epoch 473/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 474/600\n",
            "12/12 [==============================] - 12s 972ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 475/600\n",
            "12/12 [==============================] - 12s 962ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 0.9969\n",
            "Epoch 476/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 477/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 478/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 479/600\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 480/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 481/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9969\n",
            "Epoch 482/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 483/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9969\n",
            "Epoch 484/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 485/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 0.9969\n",
            "Epoch 486/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9969\n",
            "Epoch 487/600\n",
            "12/12 [==============================] - 11s 956ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9969\n",
            "Epoch 488/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9969\n",
            "Epoch 489/600\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 490/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9969\n",
            "Epoch 491/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9969\n",
            "Epoch 492/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 493/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9969\n",
            "Epoch 494/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9969\n",
            "Epoch 495/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9969\n",
            "Epoch 496/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 497/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 6.4092e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 498/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0031 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9969\n",
            "Epoch 499/600\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
            "Epoch 500/600\n",
            "12/12 [==============================] - 12s 965ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
            "Epoch 501/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0199 - val_accuracy: 0.9907\n",
            "Epoch 502/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 503/600\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 504/600\n",
            "12/12 [==============================] - 12s 972ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9969\n",
            "Epoch 505/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0093 - val_accuracy: 0.9969\n",
            "Epoch 506/600\n",
            "12/12 [==============================] - 11s 957ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 507/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 508/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0044 - accuracy: 0.9967 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 509/600\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9969\n",
            "Epoch 510/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9969\n",
            "Epoch 511/600\n",
            "12/12 [==============================] - 12s 959ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9969\n",
            "Epoch 512/600\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9969\n",
            "Epoch 513/600\n",
            "12/12 [==============================] - 12s 962ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9969\n",
            "Epoch 514/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 515/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 516/600\n",
            "12/12 [==============================] - 11s 955ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9969\n",
            "Epoch 517/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9969\n",
            "Epoch 518/600\n",
            "12/12 [==============================] - 11s 957ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9969\n",
            "Epoch 519/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 520/600\n",
            "12/12 [==============================] - 12s 965ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9969\n",
            "Epoch 521/600\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 8.6774e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 522/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 523/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 524/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 525/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 526/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 527/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 528/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.0053 - val_accuracy: 0.9969\n",
            "Epoch 529/600\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.0051 - accuracy: 0.9966 - val_loss: 0.0056 - val_accuracy: 0.9969\n",
            "Epoch 530/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 531/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 532/600\n",
            "12/12 [==============================] - 12s 966ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 533/600\n",
            "12/12 [==============================] - 12s 959ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.0136 - val_accuracy: 0.9907\n",
            "Epoch 534/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 535/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9969\n",
            "Epoch 536/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9969\n",
            "Epoch 537/600\n",
            "12/12 [==============================] - 12s 959ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 538/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 539/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9969\n",
            "Epoch 540/600\n",
            "12/12 [==============================] - 12s 967ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 541/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 542/600\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9969\n",
            "Epoch 543/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 544/600\n",
            "12/12 [==============================] - 12s 984ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9969\n",
            "Epoch 545/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 546/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 547/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0036 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 0.9969\n",
            "Epoch 548/600\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0040 - val_accuracy: 0.9969\n",
            "Epoch 549/600\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 550/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0034 - accuracy: 0.9983 - val_loss: 0.0067 - val_accuracy: 0.9969\n",
            "Epoch 551/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0099 - accuracy: 0.9949 - val_loss: 0.0040 - val_accuracy: 0.9969\n",
            "Epoch 552/600\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9969\n",
            "Epoch 553/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 554/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9969\n",
            "Epoch 555/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0064 - val_accuracy: 0.9969\n",
            "Epoch 556/600\n",
            "12/12 [==============================] - 12s 963ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9969\n",
            "Epoch 557/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 558/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9969\n",
            "Epoch 559/600\n",
            "12/12 [==============================] - 12s 965ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 560/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9969\n",
            "Epoch 561/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 562/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 563/600\n",
            "12/12 [==============================] - 11s 958ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9969\n",
            "Epoch 564/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 0.9969\n",
            "Epoch 565/600\n",
            "12/12 [==============================] - 12s 977ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 566/600\n",
            "12/12 [==============================] - 12s 979ms/step - loss: 0.0046 - accuracy: 0.9975 - val_loss: 0.0103 - val_accuracy: 0.9969\n",
            "Epoch 567/600\n",
            "12/12 [==============================] - 12s 965ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 568/600\n",
            "12/12 [==============================] - 12s 981ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 569/600\n",
            "12/12 [==============================] - 12s 959ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0079 - val_accuracy: 0.9969\n",
            "Epoch 570/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 571/600\n",
            "12/12 [==============================] - 12s 966ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 572/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9969\n",
            "Epoch 573/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9969\n",
            "Epoch 574/600\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9969\n",
            "Epoch 575/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 576/600\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9969\n",
            "Epoch 577/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 578/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 579/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 580/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 581/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 9.3761e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 582/600\n",
            "12/12 [==============================] - 12s 974ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 583/600\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 584/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.0028 - accuracy: 0.9983 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 585/600\n",
            "12/12 [==============================] - 12s 983ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 586/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 0.9969\n",
            "Epoch 587/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 0.0040 - accuracy: 0.9975 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 588/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9969\n",
            "Epoch 589/600\n",
            "12/12 [==============================] - 12s 965ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 590/600\n",
            "12/12 [==============================] - 12s 971ms/step - loss: 0.0030 - accuracy: 0.9983 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 591/600\n",
            "12/12 [==============================] - 12s 973ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 592/600\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 593/600\n",
            "12/12 [==============================] - 12s 978ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9969\n",
            "Epoch 594/600\n",
            "12/12 [==============================] - 12s 976ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 595/600\n",
            "12/12 [==============================] - 12s 980ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 596/600\n",
            "12/12 [==============================] - 12s 967ms/step - loss: 7.8615e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9969\n",
            "Epoch 597/600\n",
            "12/12 [==============================] - 12s 982ms/step - loss: 7.0934e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 598/600\n",
            "12/12 [==============================] - 12s 969ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 599/600\n",
            "12/12 [==============================] - 12s 988ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9969\n",
            "Epoch 600/600\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 5.7325e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       1.00      1.00      1.00        49\n",
            "      normal       1.00      1.00      1.00       273\n",
            "\n",
            "    accuracy                           1.00       322\n",
            "   macro avg       1.00      1.00      1.00       322\n",
            "weighted avg       1.00      1.00      1.00       322\n",
            "\n",
            "[[ 49   0]\n",
            " [  0 273]]\n",
            "acc: 1.0000\n",
            "sensitivity: 1.0000\n",
            "specificity: 1.0000\n",
            "[INFO] saving COVID-19 detector model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}